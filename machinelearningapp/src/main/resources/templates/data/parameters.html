<!DOCTYPE HTML>
<html lang="en" xmlns:th = "http://www.thymeleaf.org/">
<head th:replace="fragments :: head"></head>
<body>
    <div id="header">Set Parameters</div>

    <!--if no user-->
    <div th:replace="fragments :: links-logged-out"></div>
    <!--but, if user, .....-->

    <div id="content">
        <div class="explanation">
            <h3>Set the parameters for the machine learning algorithm. </h3>
            <p>
                The dataset will be parsed randomly into three subsets: a training set, a 
                cross-validation set, and a testing set. A model will be trained on the 
                training set using a gradient descent algorithm. Select the parameters for 
                the algorithm or use the default parameters. 
            </p>
        </div>

        <!--
            Proportion of data in training set: .1 - .9 [list]
            Initial theta0: any int
            Initial theta1: any int

            Alpha: 0-1 [list?]
            Lambda: 0+

            Max iterations: 10 - 2500
            Convergence level: .0000001 - 1 [list]
        -->
        <form method="post" th:object="${parametersDTO}" id="parameters-form">      
            <p class="errors" th:if="${#fields.hasErrors('all')}" th:errors="*{all}"></p>

            <div id="parameters-container">
                <div class="parameter-row">
                    <div class="parameter">
                        <label for="proportion">Proportion of dataset in training set: </label>
                        <input th:field="*{trainingProportion}" id="proportion" th:value=".6" />
                        <p>
                            The proportion of the original dataset that will constitute the 
                            training set. A higher number means a model will be trained
                            on a larger portion of the dataset, which could help prevent
                            the model underfitting the dataset but could lead to the 
                            model overfitting the dataset.
                        </p>
                        <p>
                            Acceptable values: .1 - .9 
                        </p>
                    </div>

                    <div class="parameter">
                        <label for="theta0">Initial theta 0: </label>
                        <input th:field="*{theta0}" id="theta0" />
                        <label for="theta1" id="theta1-label">Initial theta 1: </label>
                        <input th:field="*{theta1}" id="theta1" />
                        <p>
                            The initial values for theta. In the linear function
                            y = a + bx, theta0 takes the place of a (the y-intercept of the
                            line) and theta1 takes the place of b (the slope of the line). 
                            The gradient descent algorithm will start with these values 
                            of theta and try to find the values that result in the lowest
                            prediction error, making for a line that fits the dataset well.
                        </p>
                        <p>
                            Acceptable values: any
                        </p>
                    </div>
                </div>

                <div class="parameter-row">
                    <div class="parameter">
                        <label for="alpha">Alpha: </label>
                        <input th:field="*{alpha}" id="alpha" />
                        <p>
                            The learning rate of the gradient descent algorithm. A higher
                            number means a steeper learning rate, so the values of theta
                            will change more dramatically on each iteration of the algorithm.
                            This could result in faster learning but could also lead to 
                            the algorithm increasing prediction error on some iterations 
                            and failing to converge. 
                        </p>
                        <p>
                            Acceptable values: 0 - 1
                        </p>
                    </div>

                    <div class="parameter">
                        <label for="lambda">Lambda: </label>
                        <input th:field="*{lambda}" id="lambda" />
                        <p>
                            The regularization parameter of the algorithm. Regularization 
                            prevents the model from overfitting the data, but could also 
                            make the model underfit the data. 0 means no regularization, 
                            and a positive number means some regularization. 
                        </p>
                        <p>
                            Acceptable values: 0 - 1000
                        </p>
                    </div>
                </div>

                <div class="parameter-row">
                    <div class="parameter">
                        <label for="maxIter">Maximum iterations of gradient descent: </label>
                        <input th:field="*{maxIterations}" id="maxIter" />
                        <p>
                            The greatest number of iterations that the gradient descent
                            algorithm will execute. It will stop sooner only if it has reached
                            the convergence level. A higher number could result in a 
                            better model but will take more time. 
                        </p>
                        <p>
                            Acceptable values: 10 - 3000
                        </p>
                    </div>

                    <div class="parameter">
                        <label for="convergence">Convergence level of gradient descent: </label>
                        <input th:field="*{convergenceLevel}" id="convergence" />
                        <p>
                            The level at which the gradient descent algorithm is considered
                            to have converged, and will thus stop. The convergence level is 
                            the smallest tolerable decrease in prediction error on consecutive 
                            iterations of gradient descent. A higher number is a more lenient 
                            convergence level, which could make for shorter training but 
                            could result in a less accurate model. 
                        </p>
                        <p>
                            Acceptable values: .00000001 - 1
                        </p>
                    </div>

                </div>

                <div id="default">
                    <a th:href="@{/set-parameters?defaultParams=true}">Restore Default Parameters</a>
                </div>

                <div class="two-button-container">
                    <button type="submit" th:onclick="location.href='/view-data'">
                        View Data
                    </button>
        
                    <button type="submit" form="parameters-form">
                        Train Model
                    </button>
                </div>

            </div>
        </form>

    </div>

    <div id="footer"></div>
</body>
</html>